{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,recall_score, f1_score, precision_score, balanced_accuracy_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data2.csv')\n",
    "X = df.drop(['severity_class'], axis=1)\n",
    "y = df['severity_class'] - 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "weights = np.array([class_weights[i] for i in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11131991840670095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudor/opt/anaconda3/envs/phd_main/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression()\n",
    "logReg.fit(X_train, y_train)\n",
    "y_pred = logReg.predict(X_test)\n",
    "\n",
    "balance = balanced_accuracy_score(y_test, y_pred)\n",
    "print(balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make this work with 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = X.iloc[:int(0.8 * len(X))], X.iloc[int(0.8 * len(X)):]\n",
    "y_train1, y_test1 = y.iloc[:int(0.8 * len(y))], y.iloc[int(0.8 * len(y)):]\n",
    "\n",
    "X_train2 = np.concatenate([X.iloc[:int(0.6 * len(X))], X.iloc[int(0.8 * len(X)):]])\n",
    "X_test2  = X.iloc[int(0.6 * len(X)):int(0.8 * len(X))]\n",
    "y_train2 = np.concatenate([y.iloc[:int(0.6 * len(X))], y.iloc[int(0.8 * len(X)):]])\n",
    "y_test2  = y.iloc[int(0.6 * len(X)):int(0.8 * len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.074256666375096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudor/opt/anaconda3/envs/phd_main/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(\n",
    "    penalty='l1',       # Penalty: adds another term to the loss function;\n",
    "                        # for Lin/Log Regression - loss is the Sum of Least squares; \n",
    "                        # L1 = drops features/sets the weights to 0, L2 = makes the weights small. \n",
    "    solver='liblinear', # Solver: changes the computational algortihm/procedure to fit the model/achieve the smallest loss. \n",
    "    C = 10,             # C = 1/lambda: the coefficient of the penalty\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "logReg.fit(X_train2, y_train2)\n",
    "y_pred2 = logReg.predict(X_test2)\n",
    "\n",
    "balance = balanced_accuracy_score(y_test2, y_pred2)\n",
    "print(balance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   2.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   4.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  19.6s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  21.3s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  24.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  23.6s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  26.5s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   7.5s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   7.6s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   6.3s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   7.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   7.6s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=  49.4s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=  56.5s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=  59.7s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 1.0min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 1.1min\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  13.6s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  13.9s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=  52.4s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=  50.1s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  15.1s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  15.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=  13.6s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=  59.6s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=  53.7s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time= 1.1min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=6,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=6,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=6,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear']},\n",
       "             scoring='balanced_accuracy', verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits = 5, shuffle=False)  ### Specifies the k=5, number of splits in the cross-validation procedure\n",
    "\n",
    "logReg = LogisticRegression() ### Specify the model\n",
    "\n",
    "params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logReg,       # Model\n",
    "    param_grid=params,      # Parameter Grid: \n",
    "    scoring = 'balanced_accuracy',\n",
    "    cv=cv,\n",
    "    verbose=2,              # Print progression: 1 = very brief, 2 = detailed, 0 = none\n",
    "    n_jobs=6,               # Number of processors to use from my CPU\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "\n",
      "C: 100,  \n",
      "penalty: l1,  \n",
      "solver: liblinear,  \n"
     ]
    }
   ],
   "source": [
    "print('Best Hyperparameters:')\n",
    "print()\n",
    "best_params = grid_search.best_params_\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\"+',  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got array([3.98809524, 0.19304463, 0.60953421, ..., 0.19304463, 0.19304463,\n       0.19304463]) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m LogisticRegression(\n\u001b[1;32m      2\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  \n\u001b[1;32m      3\u001b[0m     penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[1;32m      4\u001b[0m     solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 7\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train1, y_train1)\n\u001b[1;32m      8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test1)\n\u001b[1;32m     10\u001b[0m balance \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(y_test1, y_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/phd_main/lib/python3.11/site-packages/sklearn/base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1140\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1141\u001b[0m )\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/phd_main/lib/python3.11/site-packages/sklearn/base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    640\u001b[0m         caller_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    641\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/phd_main/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got array([3.98809524, 0.19304463, 0.60953421, ..., 0.19304463, 0.19304463,\n       0.19304463]) instead."
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(\n",
    "    C=100,  \n",
    "    penalty='l1',  \n",
    "    solver='liblinear',\n",
    "    class_weight=weights,\n",
    "    )\n",
    "best_model.fit(X_train1, y_train1)\n",
    "y_pred = best_model.predict(X_test1)\n",
    "\n",
    "balance = balanced_accuracy_score(y_test1, y_pred)\n",
    "print(balance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
